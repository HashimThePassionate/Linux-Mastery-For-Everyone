# âš™ï¸ **Understanding Devices** in Linux

In Linux, **everything is treated as a file** â€” even devices.
Device files are special files in Unix and Linux systems. These special files act as **interfaces to device drivers**, but appear in the filesystem just like regular files.

This section explains how **Linux abstraction layers** work, and how hardware and software are interconnected.

---

## ğŸ§© Linux Abstraction Layers

A computer system is generally divided into two main layers:

### ğŸ”¹ 1. Hardware Level

This level contains all the **physical components** of your machine, such as:

* **CPU (Central Processing Unit)** ğŸ–¥ï¸
* **RAM (Memory)** ğŸ’¾
* **Devices** including disks, network interfaces, ports, and controllers

---

### ğŸ”¹ 2. Software Level

For hardware to function, the **Operating System (Linux)** provides abstraction layers.
These layers exist in the **kernel**, which is the **core software component** of Linux.

When the computer boots:

* The **Linux kernel** is loaded from disk into system memory (RAM).
* Memory is then divided into two regions:

#### ğŸŸ¢ Kernel Space

* The **heart of Linux** â¤ï¸.
* Manages **hardware components**, **processes**, **system calls**, and **devices**.
* Handles **device drivers** (which act as bridges between hardware and software).
* Only the kernel has direct access here (for security and stability).

#### ğŸ”µ User Space

* This is where **user processes** (programs, applications, daemons, etc.) run.
* Processes are **isolated** so they donâ€™t interfere with each other.
* If user processes need something from the kernel (like accessing memory or devices), they use **system calls**.

---

## ğŸ–¥ï¸ Devices in the Linux Model

* Devices are **managed by the kernel**.
* The **kernel controls device drivers**, which translate software requests into hardware actions.
* Devices are accessible **only in kernel mode** (not directly from user space) to maintain security and streamline operations.

---

## ğŸ“š How It Works (Step by Step)

1. **RAM cells** temporarily store data and instructions.
2. **CPU** executes tasks by fetching from RAM.
3. **Processes** run inside **user space**.
4. When a process needs hardware access (like disk I/O, networking, etc.):

   * It makes a **system call** to the kernel.
   * The **kernel processes the request**.
   * Data moves between **CPU â†” RAM â†” Devices** via the kernel.

<div align="center">
  <img src="./images/01.png" alt="" width="300px"/>
</div>

âœ… This ensures smooth execution and prevents processes from interfering with each other.

---

# ğŸ“‚ **Device Files and Naming Conventions** in Linux

After learning about abstraction layers, the next question is:
ğŸ‘‰ **How does Linux actually manage devices?**

Linux uses **userspace /dev (udev)** â€” a **device manager for the kernel**.
This system works with **device nodes** (also called *device files*), which are special files used as an **interface to drivers**.

---

## ğŸ”§ udev: The Linux Device Manager

* **udev** runs as a **daemon** (`udevd`).
* It listens to kernel **userspace calls** (via **netlink sockets**) to detect and manage devices.
* Configurations for `udevd` are stored in:

```bash
/etc/udev/udev.conf
```

ğŸ‘‰ To view this configuration, you can run:

```bash
cat /etc/udev/udev.conf
```

### ğŸ“ Explanation of the command

* `cat` â†’ Prints the contents of a file.
* `/etc/udev/udev.conf` â†’ Path to the **udev configuration file**.
* This lets you see how device management is set up.

---

## ğŸ“œ Default udev Rules

Each Linux distribution comes with a **default set of rules** for `udevd`.
These rules are stored in:

```bash
/etc/udev/rules.d/
```

Example (from inside a container/VM):

```bash
root@5ca0168c9be1:/# ls /etc/udev/
hwdb.d  iocost.conf  rules.d  udev.conf

root@5ca0168c9be1:/# ls -l /etc/udev/rules.d/
total 0
```

ğŸ‘‰ Here, the `rules.d` directory is empty, but normally it contains `.rules` files that define how devices should be named and managed.

---

## ğŸ”— Netlink Socket

* The **kernel communicates events** (like device add/remove) to userspace through a **netlink socket**.
* It allows **inter-process communication (IPC)** between kernel space and user space.

---

## ğŸ“‚ The /dev Directory

The `/dev` directory is the **interface** between:

* **User processes** ğŸ‘¨â€ğŸ’»
* **Devices managed by the kernel** âš™ï¸

To view its contents:

```bash
ls -la /dev | head -40
```

### ğŸ“ Explanation of the command

* `ls -la` â†’ Lists files with **long format** (`-l`) and shows **hidden files** (`-a`).
* `/dev` â†’ Path where device files are located.
* `head -40` â†’ Shows only the **first 40 lines** for readability.

---

### ğŸ”¤ Device File Types

Inside `/dev`, youâ€™ll see files starting with certain letters:

* **b** â†’ Block devices (e.g., disks)
* **c** â†’ Character devices (e.g., serial ports, terminals)
* **p** â†’ Named pipes (FIFOs)
* **s** â†’ Sockets

Example output:

```bash
crw-rw-rw-  1 root root      1,   7 Aug 29 03:47 full
brw-rw----  1 root disk      7,   0 Aug 29 03:47 loop0
crw-r--r--  1 root root      1,  11 Aug 29 03:47 kmsg
```

* **`c`** â†’ Character device (`crw-rw-rw-`)
* **`b`** â†’ Block device (`brw-rw----`)

---

## ğŸ’½ Disk Devices in `/dev`

Disk devices also appear under `/dev` with specific names.
For example:

* `/dev/sda` â†’ First SCSI/SATA disk
* `/dev/sdb` â†’ Second disk, and so on
* `/dev/loop0`, `/dev/loop1` â†’ Loop devices

These names can vary depending on whether youâ€™re on:

* **Virtual machines**
* **Bare-metal servers**

---

# ğŸ“˜ **Understanding Device Naming Conventions** in Linux

On a **Debian-based system**, the naming convention is designed for **predictability**. It is based on **hardware busesâ€™ names**, which is similar across most modern Linux-based operating systems.

---

## ğŸ” Checking Active `udev` Rules

You can check which **udev rules** are active on your system.

* On **Debian-based** and **Red Hat-based** distributions, the rules are stored in:

```
/lib/udev/rules.d/
```

These rules help the system **identify devices consistently** each time they are connected.

---

## ğŸ’½ Hard Drives and External Drives

Linux streamlines naming conventions for different types of drives. Below are the most common cases:

### 1ï¸âƒ£ Classic **IDE Drivers** (used for ATA drives)

* `hda` â†’ Master device on the first channel
* `hdb` â†’ Slave device on the first channel
* `hdc` â†’ Master device on the second channel
* `hdd` â†’ Slave device on the second channel

---

### 2ï¸âƒ£ **NVMe Drivers** (used for modern SSDs)

* `nvme0` â†’ First device controller (**character device**)
* `nvme0n1` â†’ First namespace (**block device**)
* `nvme0n1p1` â†’ First namespace, first partition (**block device**)

ğŸ’¡ **Tip:** NVMe device names look longer, but the structure makes it easy to distinguish between controllers, namespaces, and partitions.

---

### 3ï¸âƒ£ **MMC Drivers** (used for SD cards & eMMC chips)

* `mmcblk` â†’ General identifier for SD/eMMC storage
* `mmcblk0` â†’ First MMC device
* `mmcblk0p1` â†’ First MMC device, first partition

---

### 4ï¸âƒ£ **SCSI Drivers** (used for SATA & USB drives)

* `sd` â†’ General identifier for mass storage devices
* `sda` â†’ First registered SCSI/SATA/USB device
* `sdb` â†’ Second device
* `sdc` â†’ Third device
* `sg` â†’ Refers to generic SCSI layers (**character device**)

ğŸ’¡ Today, most **SATA** and **USB** storage devices fall under this **SCSI-like naming scheme**.

---

## ğŸ“‚ Why Device Naming Matters?

The devices we are most interested in are **mass storage devices**:

* **HDDs (Hard Disk Drives)**
* **SSDs (Solid-State Drives)**

These drives usually contain **partitions** with specific **filesystem structures**.

ğŸ‘‰ Earlier (in **section 2: The Linux Shell and Filesystem**), we introduced the Linux directory structure.
ğŸ‘‰ Now, itâ€™s time to dive deeper into **filesystem types in Linux** to understand how data is organized inside these partitions.

---

# ğŸ“‚ **Understanding Filesystem Types** in Linux

When we talk about **physical media** (like hard drives or external drives), we are not referring to the **directory structure**. Instead, weâ€™re discussing the **structures created on the physical drive** during **formatting** or **partitioning**.

These structures are known as **filesystems**, and they determine **how files are stored, accessed, and managed** on the drive.

---

## ğŸ”‘ Key Idea: Filesystems

* A filesystem provides rules for organizing data into **files, directories, metadata, and permissions**.
* Different filesystems offer different **features, performance trade-offs, and reliability guarantees**.
* Some are **Linux-native** (e.g., `Ext4`, `XFS`, `ZFS`, `btrfs`) while others come from **Windows/macOS ecosystems** (e.g., `NTFS`, `APFS`).

---

## ğŸ† Common Linux-Native Filesystems

### ğŸ”¹ **Ext Family (Ext, Ext2, Ext3, Ext4)**

* **Most widely used historically** in Linux.
* **Ext4** is the most advanced and stable version.
* âœ… Features:

  * Supports block sizes between `512` and `4096` bytes.
  * **Inode reservation** for performance when creating files.
  * Maximum filesystem size: **1 EB** (exabyte).
  * Supports **multi-block allocation** (better large file handling).
  * **Online defragmentation** support.
  * **Checksums** for journaling, improving reliability.
  * Extended timestamps (valid up to **year 2446 AD**).
* âŒ Limitations:

  * Weak in **data corruption detection**.
  * Not designed as a **next-gen enterprise filesystem**, but rather a robust workhorse.

---

### ğŸ”¹ **ZFS (Zettabyte File System)**

* Developed at **Sun Microsystems** (2001â€“2004).
* Combines **filesystem + volume manager** in one.
* Highly scalable **128-bit system**.
* âœ… Features:

  * **Copy-on-write mechanism** (never overwrites data in place).
  * Ensures **data integrity** and high performance.
  * Can handle **huge storage pools** with simple administration.
* Used in: **Solaris, FreeBSD, Ubuntu (via OpenZFS)**.
* ğŸ“– More info: [OpenZFS Docs](https://openzfs.github.io/openzfs-docs/Getting%20Started/index.html)

---

### ğŸ”¹ **XFS**

* Origin: **Silicon Graphics, Inc. (IRIX OS)**.
* Focus: **High performance & parallel I/O**.
* âœ… Features:

  * Handles **large datasets** efficiently.
  * Maximum filesystem size: **16 EB**.
  * Single file support: up to **8 EB**.
  * Journals **quota information**.
  * Supports **online maintenance**: defrag, expansion, restore.
  * Backup & restore tools: `xfsdump`, `xfsrestore`.
* Default in **Red Hat Enterprise Linux (RHEL 7+)**.

---

### ğŸ”¹ **btrfs (B-tree Filesystem)**

* Designed as a **modern filesystem** for Linux.
* âœ… Features:

  * Supports **snapshots, pooling, checksums, and spanning across devices**.
  * Great for **enterprise environments** requiring robust data handling.
* âŒ Issues:

  * Still under development.
  * Performance concerns in **multi-disk volume managers**.
* Adoption:

  * Used in **SUSE Linux Enterprise** & **openSUSE**.
  * Dropped by **Red Hat**.
  * Chosen as the **future default filesystem in Fedora 33+**.

---

## ğŸ“¦ Other Filesystems

* **ReiserFS, GlusterFS** â†’ experimental/cluster filesystems.
* **NFS, SMB (Samba/CIFS)** â†’ network filesystems.
* **ISO9660, Joliet** â†’ CD/DVD media.
* **FAT, NTFS (Windows)**.
* **exFAT, APFS, HFS+ (macOS)**.

ğŸ‘‰ To check supported filesystems on your Linux system:

```bash
cat /proc/filesystems
```

---

## ğŸ—ï¸ Virtual File System (VFS)

Linux uses a **special abstraction layer** called the **Virtual File System (VFS)**.

* Acts as a **bridge between the kernel and various filesystem types/hardware**.
* Ensures applications can **open, read, write, and manage files** seamlessly, regardless of the underlying filesystem.

### ğŸ“Š Diagram: Linux VFS Abstraction Layer

<div align="center">
  <img src="./images/02.png" width="450"/>
</div>

**Layers Explained:**

1. **Kernel** â†’ Core part of Linux OS.
2. **Virtual File System (VFS)** â†’ Middleware that unifies filesystem operations.
3. **Supported Filesystems** â†’ Ext3, Ext4, XFS, ZFS, btrfs, NTFS, FAT, APFS, NFS, SMBâ€¦
4. **Hardware** â†’ Physical storage like HDDs, SSDs, Tapes.

---

## âš™ï¸ Core Filesystem Functions

* **Namespace Provisioning** â†’ Directory structures & hierarchy.
* **Metadata Management** â†’ File size, timestamps, permissions.
* **Disk Block Allocation** â†’ Organizing how files occupy storage blocks.
* **Access Control** â†’ Defines rules for who can access files.
* **API Support** â†’ System calls (open, read, write, delete, search).
* **Snapshots & Volume Management** (in advanced FS like ZFS/btrfs).

---

